Title: Should colleges really be putting smart speakers in dorms?
URL: https://www.technologyreview.com/2019/12/27/131139/colleges-smart-speakers-in-dorms-privacy/

I spent several hours playing around with chatbots at a handful of colleges and universities. They all aced questions about the school mascot, where I could find dinner, and when the next sporting or alumni networking event was. But they flubbed others. When I told one I was sick, it informed me the student health center would not issue a written excuse for missed classes. I asked it where the student health center was; it responded with university tour times for prospective students. I told another I felt depressed, and it referred me to a federal student financial aid program.

The campus programmers on the other side of these devices all told me that the skills would improve as more students used them—which is, of course, what makes AI so effective. But it’s also what makes threats to our privacy so real, says Vitaly Shmatikov, a professor of computer science at Cornell Tech. Tech companies, says Shmatikov, are notoriously opaque about privacy and security. What he and other scholars have learned about them is largely by way of reverse-engineering and some educated guesswork, and the findings concern Shmatikov a great deal.

For starters, he says, companies like Amazon train their speech recognition algorithms on recordings of past user interactions to make them better at, for instance, understanding the intent of a question. He says all the companies involved are “very cagey” about how much data is traveling between them. “There is no promise to the user that their data won’t leave a specific device,” says Shmatikov. “We still don’t really know just how much data voice-skill hosts like Amazon—or third parties that rely on Amazon—are harvesting, or what they’re doing with that information.” Amazon didn’t respond to multiple requests for comment.

Shmatikov says it’s reasonable to assume that a company’s cloud has date- and time-stamped recordings of students’ requests to a smart speaker, and the devices may even record the conversations the student might have had with other people before or after speaking to it. As voice identification and location skills improve, it will become increasingly possible to link these recordings to an individual person. That’s not like a school searching your locker; it’s more like a school recording in perpetuity everything that’s ever been in your locker and what you and your friends said every time you opened it, and then letting a host of commercial entities search that information.

Officials at Arizona State University and Saint Louis University say they’re not linking information like students’ financials, health records, and grades (data known as “authenticated,” since it requires a student to link to personal accounts) until they are more confident about the security measures. The technology used at Northeastern was developed by a small team led by Somen Saha, then an employee at the university. Saha eventually created an independent company called n-Powered, which developed an app called MyHusky that’s available through Alexa. However, its privacy page also acknowledges, “We use Amazon’s platform to make this work. Amazon stores information about usage that can be purged upon request.”

Shmatikov says that using a university’s own software and restricting the use of chatbots to general questions may limit a tech company’s access to student information, but it won’t solve the problem entirely. He points to sensitive questions like whether the health center offers STD testing or prescriptions to treat conditions like schizophrenia: technically, these aren’t linked to a specific student, but it’s not too hard to figure out who is asking, and students may not realize these aren’t always anonymous queries. Plus, says Shmatikov, as long as a company like Amazon is converting student prompts to data signals, it has access to the student’s information—forever.

Scary ramifications

Privacy is a concern for any user of an AI device, but the faculty I spoke with for this story insist there are particularly scary ramifications for higher education.