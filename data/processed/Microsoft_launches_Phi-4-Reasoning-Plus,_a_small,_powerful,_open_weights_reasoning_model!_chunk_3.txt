nce frameworks including Hugging Face Transformers, vLLM, llama.cpp, and Ollama. Microsoft provides detailed recommendations on inference parameters and system prompt formatting to help developers get the most from the model. Outperforms larger models The model’s development reflects Microsoft’s growing emphasis on training smaller models capable of rivaling much larger systems in performance. Despite its relatively modest size, Phi-4-reasoning-plus outperforms larger open-weight models such as 