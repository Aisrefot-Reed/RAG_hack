ce benchmarks showing competitive results relative to larger models in the same series. The model is now freely available for download from: Developers can integrate the model into their pipelines using Hugging Face Transformers, Docker containers, or Alibabaâ€™s vLLM implementation. Optional optimizations such as FlashAttention 2 and BF16 precision are supported for enhanced speed and reduced memory consumption. Benchmark performance shows strong results even approaching much larger parameter mod