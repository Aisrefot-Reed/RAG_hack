lus outperforms larger open-weight models such as DeepSeek-R1-Distill-70B on a number of demanding benchmarks. On the AIME 2025 math exam, for instance, it delivers a higher average accuracy at passing all 30 questions on the first try (a feat known as “pass@1”) than the 70B parameter distillation model, and approaches the performance of DeepSeek-R1 itself, which is far larger at 671B parameters. Structured thinking via fine-tuning To achieve this, Microsoft employed a data-centric training stra