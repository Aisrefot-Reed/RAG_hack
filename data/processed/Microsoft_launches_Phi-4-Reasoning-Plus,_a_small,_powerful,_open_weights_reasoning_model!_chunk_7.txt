his led to longer but more thoughtful responses, particularly on questions where the model initially lacked confidence. Optimized for research and engineering constraints Phi-4-reasoning-plus is intended for use in applications that benefit from high-quality reasoning under memory or latency constraints. It supports a context length of 32,000 tokens by default and has demonstrated stable performance in experiments with inputs up to 64,000 tokens. It is best used in a chat-like setting and perfor